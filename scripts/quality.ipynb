{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a1f9a6df",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Chemins CSV (à modifier si besoin)\n",
        "CSV_QUALITY_RAW = \"../data/quality/quality-data.csv\"\n",
        "CSV_QUALITY_INTERPOLATED = \"../data/quality/quality-data-interpolated.csv\"\n",
        "CSV_CRISE_COMPARAISON = \"../data/quality/quality-data-with-crise.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "630998ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN restants :\n",
            " PLF      0\n",
            "CFX      0\n",
            "TOTAL    0\n",
            "dtype: int64\n",
            "Fichier sauvegardé ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3000\\2376604853.py:70: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(interpolate_group)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(CSV_QUALITY_RAW)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "def to_number(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    x = str(x).replace(\"\\u202f\", \"\").replace(\" \", \"\")\n",
        "    x = x.replace(\",\", \".\")\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "for col in [\"PLF\", \"CFX\", \"TOTAL\"]:\n",
        "    df[col] = df[col].apply(to_number)\n",
        "\n",
        "df = df.sort_values([\"INDICATEUR\", \"SOUS-INDICATEUR\", \"ANNEE\"])\n",
        "\n",
        "def interpolate_group(g):\n",
        "    indicateur, sous_indicateur = g.name\n",
        "\n",
        "    # --- Unité (on assume une seule unité par couple indicateur / sous-indicateur)\n",
        "    unite = g[\"UNITE\"].dropna().iloc[0] if \"UNITE\" in g.columns and g[\"UNITE\"].notna().any() else np.nan\n",
        "\n",
        "    # --- Proportion PLF dans (PLF+CFX) quand on l'a (pour répartir TOTAL si besoin)\n",
        "    ratio = np.nan\n",
        "    mask_known = g[\"PLF\"].notna() & g[\"CFX\"].notna() & ((g[\"PLF\"] + g[\"CFX\"]) > 0)\n",
        "    if mask_known.any():\n",
        "        ratio = (g.loc[mask_known, \"PLF\"] / (g.loc[mask_known, \"PLF\"] + g.loc[mask_known, \"CFX\"])).median()\n",
        "    if np.isnan(ratio):\n",
        "        ratio = 0.5  # fallback\n",
        "\n",
        "    g = g.set_index(\"ANNEE\")\n",
        "    year_min = min(2011, g.index.min())\n",
        "    years = range(year_min, g.index.max() + 2)\n",
        "    g = g.reindex(years)\n",
        "\n",
        "    g[\"INDICATEUR\"] = indicateur\n",
        "    g[\"SOUS-INDICATEUR\"] = sous_indicateur\n",
        "    g[\"UNITE\"] = unite\n",
        "\n",
        "    # 1) Si TOTAL existe et CFX manquant -> CFX = TOTAL - PLF\n",
        "    m = g[\"TOTAL\"].notna() & g[\"PLF\"].notna() & g[\"CFX\"].isna()\n",
        "    g.loc[m, \"CFX\"] = g.loc[m, \"TOTAL\"] - g.loc[m, \"PLF\"]\n",
        "\n",
        "    # 2) Si TOTAL existe et PLF manquant -> PLF = TOTAL - CFX\n",
        "    m = g[\"TOTAL\"].notna() & g[\"CFX\"].notna() & g[\"PLF\"].isna()\n",
        "    g.loc[m, \"PLF\"] = g.loc[m, \"TOTAL\"] - g.loc[m, \"CFX\"]\n",
        "\n",
        "    # 3) Si TOTAL existe et PLF+CFX manquent -> répartir via ratio\n",
        "    m = g[\"TOTAL\"].notna() & g[\"PLF\"].isna() & g[\"CFX\"].isna()\n",
        "    g.loc[m, \"PLF\"] = g.loc[m, \"TOTAL\"] * ratio\n",
        "    g.loc[m, \"CFX\"] = g.loc[m, \"TOTAL\"] * (1 - ratio)\n",
        "\n",
        "    # 4) Interpolation linéaire\n",
        "    g[\"PLF\"] = g[\"PLF\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
        "    g[\"CFX\"] = g[\"CFX\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
        "\n",
        "    # 5) Compléter TOTAL si manquant\n",
        "    mt = g[\"TOTAL\"].isna()\n",
        "    g.loc[mt, \"TOTAL\"] = g.loc[mt, \"PLF\"] + g.loc[mt, \"CFX\"]\n",
        "\n",
        "    # 6) Arrondir toutes les données numériques à 2 décimales\n",
        "    g[[\"PLF\", \"CFX\", \"TOTAL\"]] = g[[\"PLF\", \"CFX\", \"TOTAL\"]].round(2)\n",
        "\n",
        "    return g.reset_index().rename(columns={\"index\": \"ANNEE\"})\n",
        "\n",
        "df_interpolated = (\n",
        "    df.groupby([\"INDICATEUR\", \"SOUS-INDICATEUR\"], group_keys=False)\n",
        "      .apply(interpolate_group)\n",
        ")\n",
        "\n",
        "print(\"NaN restants :\\n\", df_interpolated[[\"PLF\",\"CFX\",\"TOTAL\"]].isna().sum())\n",
        "df_interpolated.to_csv(CSV_QUALITY_INTERPOLATED, index=False)\n",
        "print(\"Fichier sauvegardé ✅\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "091f44d2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ANNEE                         INDICATEUR SOUS-INDICATEUR  PLF_NORMAL  \\\n",
            "0   2011  Confort et propreté de la chambre             Bon       20.60   \n",
            "1   2012  Confort et propreté de la chambre             Bon       20.60   \n",
            "2   2013  Confort et propreté de la chambre             Bon       20.60   \n",
            "3   2011  Confort et propreté de la chambre       Excellent        8.75   \n",
            "4   2012  Confort et propreté de la chambre       Excellent        8.75   \n",
            "5   2013  Confort et propreté de la chambre       Excellent        8.75   \n",
            "6   2011  Confort et propreté de la chambre         Mauvais        4.38   \n",
            "7   2012  Confort et propreté de la chambre         Mauvais        4.38   \n",
            "8   2013  Confort et propreté de la chambre         Mauvais        4.38   \n",
            "9   2011  Confort et propreté de la chambre       Tres bon        15.00   \n",
            "\n",
            "   CFX_NORMAL  TOTAL_NORMAL UNITE    MODE  PLF_CRISE  CFX_CRISE  TOTAL_CRISE  \\\n",
            "0       20.60         41.20     %  Normal      35.02      35.02        70.04   \n",
            "1       20.60         41.20     %  Normal      35.02      35.02        70.04   \n",
            "2       20.60         41.20     %  Normal      35.02      35.02        70.04   \n",
            "3        8.75         17.50     %  Normal      14.88      14.88        29.76   \n",
            "4        8.75         17.50     %  Normal      14.88      14.88        29.76   \n",
            "5        8.75         17.50     %  Normal      14.88      14.88        29.76   \n",
            "6        4.38          8.75     %  Normal       7.45       7.45        14.90   \n",
            "7        4.38          8.75     %  Normal       7.45       7.45        14.90   \n",
            "8        4.38          8.75     %  Normal       7.45       7.45        14.90   \n",
            "9       15.00         30.00     %  Normal      25.50      25.50        51.00   \n",
            "\n",
            "   ECART_TOTAL  VARIATION_PCT  \n",
            "0        28.84          70.00  \n",
            "1        28.84          70.00  \n",
            "2        28.84          70.00  \n",
            "3        12.26          70.06  \n",
            "4        12.26          70.06  \n",
            "5        12.26          70.06  \n",
            "6         6.15          70.29  \n",
            "7         6.15          70.29  \n",
            "8         6.15          70.29  \n",
            "9        21.00          70.00  \n",
            "Fichier comparaison sauvegardé ✅\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(CSV_QUALITY_INTERPOLATED)\n",
        "\n",
        "# --- 1) Dataset normal\n",
        "df_normal = df.copy()\n",
        "df_normal[\"MODE\"] = \"Normal\"\n",
        "\n",
        "# --- 2) NOUVELLE APPROCHE : Redistribution pour les données en %\n",
        "# En crise, la qualité SE DÉGRADE (pas de multiplication simple)\n",
        "\n",
        "# Définir les mappings de dégradation pour chaque indicateur\n",
        "QUALITY_DEGRADATION = {\n",
        "    \"Excellent\": {\"Excellent\": 0.50, \"Tres bon\": 0.30, \"Bon\": 0.15, \"Moyen\": 0.05, \"Mauvais\": 0.00},\n",
        "    \"Tres bon\": {\"Excellent\": 0.00, \"Tres bon\": 0.40, \"Bon\": 0.40, \"Moyen\": 0.15, \"Mauvais\": 0.05},\n",
        "    \"Bon\": {\"Excellent\": 0.00, \"Tres bon\": 0.10, \"Bon\": 0.40, \"Moyen\": 0.35, \"Mauvais\": 0.15},\n",
        "    \"Moyen\": {\"Excellent\": 0.00, \"Tres bon\": 0.00, \"Bon\": 0.15, \"Moyen\": 0.45, \"Mauvais\": 0.40},\n",
        "    \"Mauvais\": {\"Excellent\": 0.00, \"Tres bon\": 0.00, \"Bon\": 0.00, \"Moyen\": 0.20, \"Mauvais\": 0.80}\n",
        "}\n",
        "\n",
        "# --- 3) Identifier les indicateurs en %\n",
        "# On traite différemment les indicateurs en % (distributions) vs valeurs absolues\n",
        "def is_percentage_indicator(row):\n",
        "    \"\"\"Détermine si un indicateur est un pourcentage (distribution)\"\"\"\n",
        "    # Vérifier si l'unité est '%'\n",
        "    if pd.notna(row['UNITE']) and row['UNITE'] == '%':\n",
        "        # Vérifier si c'est une distribution (Excellent, Bon, Mauvais, etc.)\n",
        "        sous_indic = str(row['SOUS-INDICATEUR']).strip()\n",
        "        if sous_indic in [\"Excellent\", \"Tres bon\", \"Bon\", \"Moyen\", \"Mauvais\"]:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Marquer les lignes\n",
        "df_normal['IS_PCT_DISTRIBUTION'] = df_normal.apply(is_percentage_indicator, axis=1)\n",
        "\n",
        "# --- 4) Dataset crise avec logique adaptée\n",
        "df_crise = df.copy()\n",
        "df_crise[\"MODE\"] = \"Crise\"\n",
        "df_crise['IS_PCT_DISTRIBUTION'] = df_crise.apply(is_percentage_indicator, axis=1)\n",
        "\n",
        "# Pour les pourcentages (distributions) : REDISTRIBUTION\n",
        "# Pour les autres valeurs : MULTIPLICATION par coefficient\n",
        "\n",
        "# A) Traiter les distributions en % (redistribution)\n",
        "pct_mask = df_crise['IS_PCT_DISTRIBUTION']\n",
        "\n",
        "if pct_mask.any():\n",
        "    print(f\"⚠️ {pct_mask.sum()} lignes détectées comme distributions en % → Redistribution appliquée\")\n",
        "    \n",
        "    # Grouper par ANNEE + INDICATEUR pour redistribuer\n",
        "    for (annee, indicateur), group in df_crise[pct_mask].groupby(['ANNEE', 'INDICATEUR']):\n",
        "        indices = group.index\n",
        "        \n",
        "        # Créer une nouvelle distribution dégradée\n",
        "        new_distribution = {}\n",
        "        for _, row in group.iterrows():\n",
        "            sous_indic = str(row['SOUS-INDICATEUR']).strip()\n",
        "            if sous_indic in QUALITY_DEGRADATION:\n",
        "                # Distribuer selon la matrice de dégradation\n",
        "                for target, weight in QUALITY_DEGRADATION[sous_indic].items():\n",
        "                    if target not in new_distribution:\n",
        "                        new_distribution[target] = 0\n",
        "                    # PLF et CFX traités séparément\n",
        "                    new_distribution[target] += row['PLF'] * weight\n",
        "        \n",
        "        # Normaliser pour sommer à 100% (au cas où)\n",
        "        total_new = sum(new_distribution.values())\n",
        "        if total_new > 0:\n",
        "            for key in new_distribution:\n",
        "                new_distribution[key] = (new_distribution[key] / total_new) * 100\n",
        "        \n",
        "        # Appliquer les nouvelles valeurs\n",
        "        for idx, row in group.iterrows():\n",
        "            sous_indic = str(row['SOUS-INDICATEUR']).strip()\n",
        "            if sous_indic in new_distribution:\n",
        "                # Appliquer le même ratio PLF/CFX qu'en normal\n",
        "                ratio_plf = row['PLF'] / row['TOTAL'] if row['TOTAL'] > 0 else 0.5\n",
        "                df_crise.loc[idx, 'PLF'] = round(new_distribution[sous_indic] * ratio_plf, 2)\n",
        "                df_crise.loc[idx, 'CFX'] = round(new_distribution[sous_indic] * (1 - ratio_plf), 2)\n",
        "                df_crise.loc[idx, 'TOTAL'] = round(new_distribution[sous_indic], 2)\n",
        "\n",
        "# B) Pour les autres indicateurs (valeurs absolues, scores, etc.) : MULTIPLICATION classique\n",
        "non_pct_mask = ~df_crise['IS_PCT_DISTRIBUTION']\n",
        "\n",
        "if non_pct_mask.any():\n",
        "    print(f\"✅ {non_pct_mask.sum()} lignes traitées avec coefficient ×1.70 (valeurs non-distributions)\")\n",
        "    COEF_CRISE_GLOBAL = 1.70\n",
        "    df_crise.loc[non_pct_mask, \"PLF\"] = (df_crise.loc[non_pct_mask, \"PLF\"] * COEF_CRISE_GLOBAL).round(2)\n",
        "    df_crise.loc[non_pct_mask, \"CFX\"] = (df_crise.loc[non_pct_mask, \"CFX\"] * COEF_CRISE_GLOBAL).round(2)\n",
        "    df_crise.loc[non_pct_mask, \"TOTAL\"] = (df_crise.loc[non_pct_mask, \"PLF\"] + df_crise.loc[non_pct_mask, \"CFX\"]).round(2)\n",
        "\n",
        "# --- 5) Calcul évolution (Crise vs Normal)\n",
        "merge_cols = [\"ANNEE\", \"INDICATEUR\", \"SOUS-INDICATEUR\"]\n",
        "\n",
        "df_compare = df_normal.merge(\n",
        "    df_crise[merge_cols + [\"PLF\", \"CFX\", \"TOTAL\"]],\n",
        "    on=merge_cols,\n",
        "    suffixes=(\"_NORMAL\", \"_CRISE\")\n",
        ")\n",
        "\n",
        "# Écart en valeur et variation en %\n",
        "df_compare[\"ECART_TOTAL\"] = (df_compare[\"TOTAL_CRISE\"] - df_compare[\"TOTAL_NORMAL\"]).round(2)\n",
        "df_compare[\"VARIATION_PCT\"] = ((df_compare[\"ECART_TOTAL\"] / df_compare[\"TOTAL_NORMAL\"]) * 100).round(2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"APERÇU DES DONNÉES (10 premières lignes)\")\n",
        "print(\"=\"*80)\n",
        "print(df_compare.head(10))\n",
        "\n",
        "# Vérification : somme des % par indicateur/année\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VÉRIFICATION : Somme des distributions en % (doit = 100%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "check_pct = df_compare[df_compare['UNITE'] == '%'].copy()\n",
        "if not check_pct.empty:\n",
        "    check_pct['SOUS_CLEAN'] = check_pct['SOUS-INDICATEUR'].str.strip()\n",
        "    \n",
        "    # Filtrer uniquement les distributions (Excellent, Bon, etc.)\n",
        "    quality_categories = [\"Excellent\", \"Tres bon\", \"Bon\", \"Moyen\", \"Mauvais\"]\n",
        "    check_pct_dist = check_pct[check_pct['SOUS_CLEAN'].isin(quality_categories)]\n",
        "    \n",
        "    if not check_pct_dist.empty:\n",
        "        sums_normal = check_pct_dist.groupby(['ANNEE', 'INDICATEUR'])['TOTAL_NORMAL'].sum()\n",
        "        sums_crise = check_pct_dist.groupby(['ANNEE', 'INDICATEUR'])['TOTAL_CRISE'].sum()\n",
        "        \n",
        "        print(\"\\nSOMMES MODE NORMAL (5 premiers):\")\n",
        "        print(sums_normal.head())\n",
        "        print(f\"\\n→ Toutes les sommes = 100% ? {(sums_normal.round(0) == 100).all()}\")\n",
        "        \n",
        "        print(\"\\nSOMMES MODE CRISE (5 premiers):\")\n",
        "        print(sums_crise.head())\n",
        "        print(f\"→ Toutes les sommes = 100% ? {(sums_crise.round(0) == 100).all()}\")\n",
        "\n",
        "# Sauvegarde\n",
        "df_compare.to_csv(CSV_CRISE_COMPARAISON, index=False)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✅ Fichier comparaison sauvegardé avec logique adaptée aux distributions !\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
